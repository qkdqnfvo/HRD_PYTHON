{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./kaggle/credit_card_fraud_detection/creditcard.csv')\n",
    "\n",
    "def get_preprocessed_df(df=None):\n",
    "    df_copy = df.copy()\n",
    "    df_copy.drop('Time', axis=1, inplace=True)\n",
    "    return df_copy\n",
    "\n",
    "def get_train_test_dataset(df=None):\n",
    "    df_copy = get_preprocessed_df(df)\n",
    "    X = df_copy.iloc[:, :-1]\n",
    "    Y = df_copy.iloc[:, -1]\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X ,Y, test_size=0.3, stratify=Y)\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def get_clf_eval(Y_test, pred, pred_proba=None):\n",
    "    confusion = confusion_matrix(Y_test, pred)\n",
    "    acc = accuracy_score(Y_test, pred)\n",
    "    precision = precision_score(Y_test, pred)\n",
    "    recall = recall_score(Y_test, pred)\n",
    "    f1 = f1_score(Y_test, pred)\n",
    "    roc_auc = roc_auc_score(Y_test, pred_proba)\n",
    "    print('Confusion matrix')\n",
    "    print(confusion)\n",
    "    print('acc: {:.4f}, precision: {:.4f}, recall: {:.4f}, F1: {:.4f}, roc_auc: {:.4f}'.format(acc, precision, recall, f1, roc_auc))\n",
    "    # print(f'acc: {acc:.4f}, precision: {precision:.4f}, recall: {recall:.4f}, F1: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = get_train_test_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85282    13]\n",
      " [   54    94]]\n",
      "acc: 0.9992, precision: 0.8785, recall: 0.6351, F1: 0.7373, roc_auc: 0.9734\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "lr_clf.fit(X_train, Y_train)\n",
    "lr_pred = lr_clf.predict(X_test)\n",
    "lr_pred_proba = lr_clf.predict_proba(X_test)[:, 1]\n",
    "get_clf_eval(Y_test, lr_pred, lr_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_train_eval(model, X_train, X_test, Y_train, Y_test):\n",
    "    model.fit(X_train, Y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    pred_proba = model.predict_proba(X_test)[:, -1]\n",
    "    get_clf_eval(Y_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85282    13]\n",
      " [   54    94]]\n",
      "acc: 0.9992, precision: 0.8785, recall: 0.6351, F1: 0.7373, roc_auc: 0.9734\n"
     ]
    }
   ],
   "source": [
    "get_model_train_eval(lr_clf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85287     8]\n",
      " [   32   116]]\n",
      "acc: 0.9995, precision: 0.9355, recall: 0.7838, F1: 0.8529, roc_auc: 0.9806\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df['Amount', bins=100, kde=True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_df(df=None):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    df_copy = df.copy()\n",
    "    scaler = StandardScaler()\n",
    "    amount_n = scaler.fit_transform(df_copy['Amount'].values.reshape(-1, 1))\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    df_copy.drop('Time', axis=1, inplace=True)\n",
    "    return df_copy\n",
    "X_train, X_test, Y_train, Y_test = get_train_test_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85282    13]\n",
      " [   54    94]]\n",
      "acc: 0.9992, precision: 0.8785, recall: 0.6351, F1: 0.7373, roc_auc: 0.9732\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "get_model_train_eval(lr_clf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85289     6]\n",
      " [   24   124]]\n",
      "acc: 0.9996, precision: 0.9538, recall: 0.8378, F1: 0.8921, roc_auc: 0.9797\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_df(df=None):\n",
    "    import numpy as np\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    amount_n = np.log1p(df_copy['Amount'].values.reshape(-1, 1))\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    df_copy.drop('Time', axis=1, inplace=True)\n",
    "    return df_copy\n",
    "X_train, X_test, Y_train, Y_test = get_train_test_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85282    13]\n",
      " [   51    97]]\n",
      "acc: 0.9993, precision: 0.8818, recall: 0.6554, F1: 0.7519, roc_auc: 0.9746\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "get_model_train_eval(lr_clf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85290     5]\n",
      " [   25   123]]\n",
      "acc: 0.9996, precision: 0.9609, recall: 0.8311, F1: 0.8913, roc_auc: 0.9758\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier(df, column, weight=1.5):\n",
    "    import numpy as np\n",
    "    fraud = df[df['Class']==1][column]\n",
    "    q_25 = np.percentile(fraud.values, 25)\n",
    "    q_75 = np.percentile(fraud.values, 75)\n",
    "    print(q_25, q_75)\n",
    "    iqr = q_75 - q_25\n",
    "    iqr_weight = iqr * weight\n",
    "    lowest_val = q_25 - iqr_weight\n",
    "    highest_val = q_75 + iqr_weight\n",
    "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n",
    "    return outlier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.692722964972386 -4.282820849486865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([8296, 8615, 9035, 9252], dtype='int64')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_outlier(df, 'V14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.692722964972386 -4.282820849486865\n"
     ]
    }
   ],
   "source": [
    "def get_preprocessed_df(df=None):\n",
    "    import numpy as np\n",
    "\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    amount_n = np.log1p(df_copy['Amount'].values.reshape(-1, 1))\n",
    "    df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
    "    df_copy.drop('Time', axis=1, inplace=True)\n",
    "    outlier_index = get_outlier(df, 'V14')\n",
    "    df_copy.drop(outlier_index, inplace=True)\n",
    "    return df_copy\n",
    "X_train, X_test, Y_train, Y_test = get_train_test_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85287     8]\n",
      " [   56    90]]\n",
      "acc: 0.9993, precision: 0.9184, recall: 0.6164, F1: 0.7377, roc_auc: 0.9681\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "get_model_train_eval(lr_clf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85293     2]\n",
      " [   32   114]]\n",
      "acc: 0.9996, precision: 0.9828, recall: 0.7808, F1: 0.8702, roc_auc: 0.9816\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398040, 30), (398040,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=0)\n",
    "X_train_over, Y_train_over = smote.fit_resample(X_train, Y_train)\n",
    "X_train_over.shape, Y_train_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    199020\n",
       " 1       342\n",
       " Name: Class, dtype: int64,\n",
       " 0    199020\n",
       " 1    199020\n",
       " Name: Class, dtype: int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts(), Y_train_over.value_counts(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[83798  1497]\n",
      " [   13   133]]\n",
      "acc: 0.9823, precision: 0.0816, recall: 0.9110, F1: 0.1498, roc_auc: 0.9760\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "get_model_train_eval(lr_clf, X_train_over, X_test, Y_train_over, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n",
      "  File \"C:\\Users\\Pringles\\AppData\\Local\\Temp\\ipykernel_12580\\2560497996.py\", line 24, in <cell line: 24>\n",
      "    precision_recall_curve_plot(Y_test, lr_clf.predict_proba(X_test)[:, 1])\n",
      "  File \"C:\\Users\\Pringles\\AppData\\Local\\Temp\\ipykernel_12580\\2560497996.py\", line 2, in precision_recall_curve_plot\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\matplotlib\\pyplot.py\", line 31, in <module>\n",
      "    import matplotlib.colorbar\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\matplotlib\\colorbar.py\", line 36, in <module>\n",
      "    import matplotlib.contour as contour\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\matplotlib\\contour.py\", line 23, in <module>\n",
      "    import matplotlib.text as text\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\matplotlib\\text.py\", line 22, in <module>\n",
      "    from .textpath import TextPath  # Unused, but imported by others.\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\matplotlib\\textpath.py\", line 20, in <module>\n",
      "    from matplotlib.mathtext import MathTextParser\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\matplotlib\\mathtext.py\", line 38, in <module>\n",
      "    from matplotlib import _png, colors as mcolors, get_data_path, rcParams\n",
      "ImportError: DLL load failed while importing _png: 메모리 리소스가 부족하여 이 명령을 처리할 수 없습니다.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1993, in showtraceback\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "  File \"d:\\Users\\Pringles\\anaconda3\\envs\\hrd\\lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "def precision_recall_curve_plot(y_test , pred_proba_c1):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.ticker as tkicker\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "    precisions, recalls, thresholds = precision_recall_curve( y_test, pred_proba_c1)\n",
    "    \n",
    "    # X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "    plt.figure(figsize=(8,6))\n",
    "    threshold_boundary = thresholds.shape[0]\n",
    "    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')\n",
    "    plt.plot(thresholds, recalls[0:threshold_boundary],label='recall')\n",
    "    \n",
    "    # threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "    start, end = plt.xlim()\n",
    "    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "    \n",
    "    # x축, y축 label과 legend, 그리고 grid 설정\n",
    "    plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "    plt.legend(); plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "precision_recall_curve_plot(Y_test, lr_clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "[[85279    16]\n",
      " [   28   118]]\n",
      "acc: 0.9995, precision: 0.8806, recall: 0.8082, F1: 0.8429, roc_auc: 0.9779\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=1, boost_from_average=False)\n",
    "get_model_train_eval(lgbm_clf, X_train_over, X_test, Y_train_over, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('hrd')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c2e67704c6d152f142b8c3106687cd2194e93bf9cff81b34c8c3689f569f836"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
